# services/trends_scraper.py
from pytrends.request import TrendReq
import pandas as pd
from typing import List, Dict, Optional
import time
import random
from datetime import datetime, timedelta

class GoogleTrendsScraper:
    def __init__(self, use_proxies=False):
        """
        Args:
            use_proxies: Náº¿u True, sá»­ dá»¥ng proxy Ä‘á»ƒ trÃ¡nh rate limit
        """
        self.use_proxies = use_proxies
        self.pytrends = self._create_pytrends_client()
        self.max_retries = 5
        self.base_delay = 2  # seconds
    
    def _create_pytrends_client(self):
        """Táº¡o pytrends client vá»›i hoáº·c khÃ´ng cÃ³ proxy"""
        proxies = None
        if self.use_proxies:
            # ThÃªm proxy cá»§a báº¡n vÃ o Ä‘Ã¢y
            # proxies = ['http://proxy1:port', 'http://proxy2:port']
            pass
        
        return TrendReq(
            hl='vi-VN',
            tz=420,
            timeout=(10, 25)
        )
    
    def _exponential_backoff(self, attempt: int):
        """Exponential backoff vá»›i jitter"""
        delay = self.base_delay * (2 ** attempt) + random.uniform(0, 1)
        max_delay = 60  # Tá»‘i Ä‘a 60 giÃ¢y
        return min(delay, max_delay)
    
    def _safe_request(self, func, *args, **kwargs):
        """Wrapper Ä‘á»ƒ retry request vá»›i exponential backoff"""
        for attempt in range(self.max_retries):
            try:
                # Delay trÆ°á»›c má»—i request Ä‘á»ƒ trÃ¡nh rate limit
                if attempt > 0:
                    delay = self._exponential_backoff(attempt)
                    print(f"â³ Retry {attempt}/{self.max_retries} - Äá»£i {delay:.1f}s...")
                    time.sleep(delay)
                else:
                    # Delay ngáº«u nhiÃªn 2-5 giÃ¢y cho request Ä‘áº§u tiÃªn
                    time.sleep(random.uniform(2, 5))
                
                result = func(*args, **kwargs)
                return result
                
            except Exception as e:
                error_msg = str(e)
                
                if "429" in error_msg or "Too Many Requests" in error_msg:
                    if attempt < self.max_retries - 1:
                        print(f"âš ï¸ Rate limit hit (429) - Retry {attempt + 1}/{self.max_retries}")
                        continue
                    else:
                        print(f"âŒ ÄÃ£ vÆ°á»£t quÃ¡ sá»‘ láº§n retry. Vui lÃ²ng Ä‘á»£i 5-10 phÃºt vÃ  thá»­ láº¡i.")
                        return None
                
                elif "400" in error_msg:
                    print(f"âŒ Bad request (400) - Kiá»ƒm tra láº¡i parameters")
                    return None
                
                else:
                    print(f"âŒ Lá»—i: {error_msg}")
                    if attempt < self.max_retries - 1:
                        continue
                    return None
        
        return None
    
    def get_coffee_trends_24h(self) -> List[Dict]:
        """Láº¥y dá»¯ liá»‡u Google Trends vá» cÃ  phÃª táº¡i Viá»‡t Nam trong 24h qua"""
        print("ğŸ“Š Äang láº¥y trends 24h...")
        
        def fetch_trends():
            # Giáº£m sá»‘ keywords xuá»‘ng 1-2 Ä‘á»ƒ trÃ¡nh rate limit
            keywords = ['cÃ  phÃª']
            
            self.pytrends.build_payload(
                kw_list=keywords,
                cat=0,
                timeframe='now 1-d',
                geo='VN',
                gprop=''
            )
            
            trends_data = self.pytrends.interest_over_time()
            
            if trends_data.empty:
                return []
            
            if 'isPartial' in trends_data.columns:
                trends_data = trends_data.drop('isPartial', axis=1)
            
            trends = []
            for idx, row in trends_data.iterrows():
                for keyword in keywords:
                    if keyword in row:
                        trends.append({
                            "timestamp": idx.strftime("%Y-%m-%d %H:%M:%S"),
                            "date": idx.strftime("%Y-%m-%d"),
                            "hour": idx.strftime("%H:%M"),
                            "keyword": keyword,
                            "interest_score": int(row[keyword]) if pd.notna(row[keyword]) else 0,
                            "country": "VN"
                        })
            
            return trends
        
        return self._safe_request(fetch_trends) or []
    
    def get_coffee_trends_hourly(self) -> List[Dict]:
        """Láº¥y trends theo giá» (4 giá» qua)"""
        print("â° Äang láº¥y hourly trends...")
        
        def fetch_hourly():
            self.pytrends.build_payload(
                kw_list=['cÃ  phÃª'],
                timeframe='now 4-H',
                geo='VN',
                gprop=''
            )
            
            trends_data = self.pytrends.interest_over_time()
            
            if trends_data.empty:
                return []
            
            if 'isPartial' in trends_data.columns:
                trends_data = trends_data.drop('isPartial', axis=1)
            
            trends = []
            for idx, row in trends_data.iterrows():
                if 'cÃ  phÃª' in row:
                    trends.append({
                        "timestamp": idx.strftime("%Y-%m-%d %H:%M:%S"),
                        "keyword": "cÃ  phÃª",
                        "interest_score": int(row['cÃ  phÃª']) if pd.notna(row['cÃ  phÃª']) else 0,
                        "country": "VN"
                    })
            
            return trends
        
        return self._safe_request(fetch_hourly) or []
    
    def get_related_queries(self) -> Dict:
        """Láº¥y cÃ¡c queries liÃªn quan Ä‘áº¿n cÃ  phÃª"""
        print("ğŸ” Äang láº¥y related queries...")
        
        def fetch_related():
            self.pytrends.build_payload(
                kw_list=['cÃ  phÃª'],
                geo='VN',
                timeframe='now 1-d'
            )
            
            return self.pytrends.related_queries()
        
        return self._safe_request(fetch_related) or {}
    
    def get_interest_by_region(self) -> pd.DataFrame:
        """Láº¥y interest theo tá»‰nh thÃ nh VN"""
        print("ğŸ—ºï¸ Äang láº¥y regional interest...")
        
        def fetch_regional():
            self.pytrends.build_payload(
                kw_list=['cÃ  phÃª'],
                geo='VN',
                timeframe='now 1-d'
            )
            
            return self.pytrends.interest_by_region(resolution='REGION', inc_low_vol=True)
        
        result = self._safe_request(fetch_regional)
        return result if result is not None else pd.DataFrame()
    
    def get_trending_searches_realtime(self) -> List[Dict]:
        """Láº¥y trending searches realtime táº¡i Viá»‡t Nam"""
        print("âš¡ Äang láº¥y realtime trends...")
        
        def fetch_realtime():
            trending_searches = self.pytrends.trending_searches(pn='vietnam')
            
            if trending_searches.empty:
                return []
            
            coffee_keywords = ['cÃ  phÃª', 'cafe', 'coffee', 'caphe']
            trending = []
            
            for idx, keyword in trending_searches[0].items():
                keyword_lower = keyword.lower()
                if any(coffee_kw in keyword_lower for coffee_kw in coffee_keywords):
                    trending.append({
                        "keyword": keyword,
                        "rank": idx + 1,
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    })
            
            return trending
        
        return self._safe_request(fetch_realtime) or []

# Test vá»›i rate limiting Ä‘Æ°á»£c cáº£i thiá»‡n
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ KHá»I Äá»˜NG GOOGLE TRENDS SCRAPER")
    print("=" * 60)
    print("\nâš ï¸ LÆ¯U Ã:")
    print("  - Script sáº½ tá»± Ä‘á»™ng retry khi gáº·p rate limit")
    print("  - CÃ³ delay giá»¯a cÃ¡c requests Ä‘á»ƒ trÃ¡nh bá»‹ block")
    print("  - Náº¿u bá»‹ 429, vui lÃ²ng Ä‘á»£i 5-10 phÃºt trÆ°á»›c khi cháº¡y láº¡i")
    print("\n" + "=" * 60 + "\n")
    
    scraper = GoogleTrendsScraper()
    
    # 1. Láº¥y trends 24h
    print("\nğŸ“Š 1. TRENDS 24 GIá»œ QUA:")
    trends_24h = scraper.get_coffee_trends_24h()
    
    if trends_24h:
        print(f"âœ… TÃ¬m tháº¥y {len(trends_24h)} data points")
        print("\nğŸ” Top 10 data points gáº§n nháº¥t:")
        for i, trend in enumerate(trends_24h[-10:], 1):
            print(f"  {i}. {trend['timestamp']} - {trend['keyword']}: {trend['interest_score']}")
        
        avg_score = sum(t['interest_score'] for t in trends_24h) / len(trends_24h)
        print(f"\nğŸ“ˆ Average Interest Score (24h): {avg_score:.2f}")
        
        df = pd.DataFrame(trends_24h)
        df.to_csv('coffee_trends_24h.csv', index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ ÄÃ£ lÆ°u data vÃ o: coffee_trends_24h.csv")
    else:
        print("âŒ KhÃ´ng láº¥y Ä‘Æ°á»£c data 24h")
        print("ğŸ’¡ Tip: Äá»£i 5-10 phÃºt vÃ  cháº¡y láº¡i script")
    
    # 2. Hourly trends (chá»‰ cháº¡y náº¿u 24h thÃ nh cÃ´ng)
    if trends_24h:
        print("\n" + "=" * 60)
        print("â° 2. TRENDS THEO GIá»œ (4 GIá»œ QUA):")
        hourly_trends = scraper.get_coffee_trends_hourly()
        
        if hourly_trends:
            print(f"âœ… TÃ¬m tháº¥y {len(hourly_trends)} data points")
            print("\nğŸ” Top 10 data points gáº§n nháº¥t:")
            for i, trend in enumerate(hourly_trends[-10:], 1):
                print(f"  {i}. {trend['timestamp']}: {trend['interest_score']}")
        else:
            print("âŒ KhÃ´ng láº¥y Ä‘Æ°á»£c hourly data")
    
    # 3. Related queries
    if trends_24h:
        print("\n" + "=" * 60)
        print("ğŸ” 3. RELATED QUERIES (24H):")
        related = scraper.get_related_queries()
        
        if 'cÃ  phÃª' in related:
            if related['cÃ  phÃª']['top'] is not None and not related['cÃ  phÃª']['top'].empty:
                print("\nğŸ”¥ Top Queries:")
                top_queries = related['cÃ  phÃª']['top'].head(10)
                for idx, row in top_queries.iterrows():
                    print(f"  {idx+1}. {row['query']} - Score: {row['value']}")
            
            if related['cÃ  phÃª']['rising'] is not None and not related['cÃ  phÃª']['rising'].empty:
                print("\nğŸ“ˆ Rising Queries:")
                rising = related['cÃ  phÃª']['rising'].head(5)
                for idx, row in rising.iterrows():
                    print(f"  {idx+1}. {row['query']} - Growth: {row['value']}")
    
    # 4. Regional interest
    if trends_24h:
        print("\n" + "=" * 60)
        print("ğŸ—ºï¸ 4. INTEREST THEO Tá»ˆNH THÃ€NH:")
        regional = scraper.get_interest_by_region()
        
        if not regional.empty and 'cÃ  phÃª' in regional.columns:
            top_regions = regional.nlargest(5, 'cÃ  phÃª')
            for region, value in top_regions['cÃ  phÃª'].items():
                print(f"  ğŸ“ {region}: {value}")
    
    print("\n" + "=" * 60)
    print("âœ… HOÃ€N THÃ€NH!")
    print("=" * 60)